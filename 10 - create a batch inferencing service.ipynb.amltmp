{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Batch Inferencing Service\n",
        "\n",
        "Imagine a health clinic takes patient measurements all day, saving the details for each patient in a separate file. Then overnight, the diabetes prediction model can be used to process all of the day's patient data as a batch, generating predictions that will be waiting the following morning so that the clinic can follow up with patients who are predicted to be at risk of diabetes. With Azure Machine Learning, you can accomplish this by creating a *batch inferencing pipeline*; and that's what you'll implement in this exercise."
      ],
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to use Azure ML 1.27.0 to work with oneweek\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1621437513897
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and register a model\n",
        "\n",
        "Now let's train and register a model to deploy in a batch inferencing pipeline."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name='mslearn-train-diabetes')\n",
        "run = experiment.start_logging()\n",
        "print(\"Starting experiment:\", experiment.name)\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = pd.read_csv('data/diabetes.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the trained model\n",
        "model_file = 'diabetes_model.pkl'\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
        "\n",
        "# Complete the run\n",
        "run.complete()\n",
        "\n",
        "# Register the model\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Inline Training'},\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "print('Model trained and registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting experiment: mslearn-train-diabetes\n",
            "Loading Data...\n",
            "Training a decision tree model\n",
            "Accuracy: 0.8913333333333333\n",
            "AUC: 0.8793273297178963\n",
            "Model trained and registered.\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1621437547629
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate and upload batch data\n",
        "\n",
        "Since we don't actually have a fully staffed clinic with patients from whom to get new data for this exercise, you'll generate a random sample from our diabetes CSV file, upload that data to a datastore in the Azure Machine Learning workspace, and register a dataset for it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Datastore, Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Set default data store\n",
        "ws.set_default_datastore('workspaceblobstore')\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "# Enumerate all datastores, indicating which is the default\n",
        "for ds_name in ws.datastores:\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\n",
        "\n",
        "# Load the diabetes data\n",
        "diabetes = pd.read_csv('data/diabetes2.csv')\n",
        "# Get a 100-item sample of the feature columns (not the diabetic label)\n",
        "sample = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].sample(n=100).values\n",
        "\n",
        "# Create a folder\n",
        "batch_folder = './batch-data'\n",
        "os.makedirs(batch_folder, exist_ok=True)\n",
        "print(\"Folder created!\")\n",
        "\n",
        "# Save each sample as a separate file\n",
        "print(\"Saving files...\")\n",
        "for i in range(100):\n",
        "    fname = str(i+1) + '.csv'\n",
        "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\n",
        "print(\"files saved!\")\n",
        "\n",
        "# Upload the files to the default datastore\n",
        "print(\"Uploading files to datastore...\")\n",
        "default_ds = ws.get_default_datastore()\n",
        "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\n",
        "\n",
        "# Register a dataset for the input data\n",
        "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\n",
        "try:\n",
        "    batch_data_set = batch_data_set.register(workspace=ws, \n",
        "                                             name='batch-data',\n",
        "                                             description='batch data',\n",
        "                                             create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "azureml_globaldatasets - Default = False\n",
            "workspaceblobstore - Default = True\n",
            "workspacefilestore - Default = False\n",
            "Folder created!\n",
            "Saving files...\n",
            "files saved!\n",
            "Uploading files to datastore...\n",
            "Uploading an estimated of 100 files\n",
            "Uploading batch-data/1.csv\n",
            "Uploaded batch-data/1.csv, 1 files out of an estimated total of 100\n",
            "Uploading batch-data/10.csv\n",
            "Uploaded batch-data/10.csv, 2 files out of an estimated total of 100\n",
            "Uploading batch-data/100.csv\n",
            "Uploaded batch-data/100.csv, 3 files out of an estimated total of 100\n",
            "Uploading batch-data/11.csv\n",
            "Uploaded batch-data/11.csv, 4 files out of an estimated total of 100\n",
            "Uploading batch-data/12.csv\n",
            "Uploaded batch-data/12.csv, 5 files out of an estimated total of 100\n",
            "Uploading batch-data/13.csv\n",
            "Uploaded batch-data/13.csv, 6 files out of an estimated total of 100\n",
            "Uploading batch-data/14.csv\n",
            "Uploaded batch-data/14.csv, 7 files out of an estimated total of 100\n",
            "Uploading batch-data/15.csv\n",
            "Uploaded batch-data/15.csv, 8 files out of an estimated total of 100\n",
            "Uploading batch-data/16.csv\n",
            "Uploaded batch-data/16.csv, 9 files out of an estimated total of 100\n",
            "Uploading batch-data/17.csv\n",
            "Uploaded batch-data/17.csv, 10 files out of an estimated total of 100\n",
            "Uploading batch-data/18.csv\n",
            "Uploaded batch-data/18.csv, 11 files out of an estimated total of 100\n",
            "Uploading batch-data/19.csv\n",
            "Uploaded batch-data/19.csv, 12 files out of an estimated total of 100\n",
            "Uploading batch-data/2.csv\n",
            "Uploaded batch-data/2.csv, 13 files out of an estimated total of 100\n",
            "Uploading batch-data/20.csv\n",
            "Uploaded batch-data/20.csv, 14 files out of an estimated total of 100\n",
            "Uploading batch-data/21.csv\n",
            "Uploaded batch-data/21.csv, 15 files out of an estimated total of 100\n",
            "Uploading batch-data/22.csv\n",
            "Uploaded batch-data/22.csv, 16 files out of an estimated total of 100\n",
            "Uploading batch-data/23.csv\n",
            "Uploaded batch-data/23.csv, 17 files out of an estimated total of 100\n",
            "Uploading batch-data/24.csv\n",
            "Uploaded batch-data/24.csv, 18 files out of an estimated total of 100\n",
            "Uploading batch-data/25.csv\n",
            "Uploaded batch-data/25.csv, 19 files out of an estimated total of 100\n",
            "Uploading batch-data/26.csv\n",
            "Uploaded batch-data/26.csv, 20 files out of an estimated total of 100\n",
            "Uploading batch-data/27.csv\n",
            "Uploaded batch-data/27.csv, 21 files out of an estimated total of 100\n",
            "Uploading batch-data/28.csv\n",
            "Uploaded batch-data/28.csv, 22 files out of an estimated total of 100\n",
            "Uploading batch-data/29.csv\n",
            "Uploaded batch-data/29.csv, 23 files out of an estimated total of 100\n",
            "Uploading batch-data/3.csv\n",
            "Uploaded batch-data/3.csv, 24 files out of an estimated total of 100\n",
            "Uploading batch-data/30.csv\n",
            "Uploaded batch-data/30.csv, 25 files out of an estimated total of 100\n",
            "Uploading batch-data/31.csv\n",
            "Uploaded batch-data/31.csv, 26 files out of an estimated total of 100\n",
            "Uploading batch-data/32.csv\n",
            "Uploaded batch-data/32.csv, 27 files out of an estimated total of 100\n",
            "Uploading batch-data/33.csv\n",
            "Uploaded batch-data/33.csv, 28 files out of an estimated total of 100\n",
            "Uploading batch-data/34.csv\n",
            "Uploaded batch-data/34.csv, 29 files out of an estimated total of 100\n",
            "Uploading batch-data/35.csv\n",
            "Uploaded batch-data/35.csv, 30 files out of an estimated total of 100\n",
            "Uploading batch-data/36.csv\n",
            "Uploaded batch-data/36.csv, 31 files out of an estimated total of 100\n",
            "Uploading batch-data/37.csv\n",
            "Uploaded batch-data/37.csv, 32 files out of an estimated total of 100\n",
            "Uploading batch-data/38.csv\n",
            "Uploaded batch-data/38.csv, 33 files out of an estimated total of 100\n",
            "Uploading batch-data/39.csv\n",
            "Uploaded batch-data/39.csv, 34 files out of an estimated total of 100\n",
            "Uploading batch-data/4.csv\n",
            "Uploaded batch-data/4.csv, 35 files out of an estimated total of 100\n",
            "Uploading batch-data/40.csv\n",
            "Uploaded batch-data/40.csv, 36 files out of an estimated total of 100\n",
            "Uploading batch-data/41.csv\n",
            "Uploaded batch-data/41.csv, 37 files out of an estimated total of 100\n",
            "Uploading batch-data/42.csv\n",
            "Uploaded batch-data/42.csv, 38 files out of an estimated total of 100\n",
            "Uploading batch-data/43.csv\n",
            "Uploaded batch-data/43.csv, 39 files out of an estimated total of 100\n",
            "Uploading batch-data/44.csv\n",
            "Uploaded batch-data/44.csv, 40 files out of an estimated total of 100\n",
            "Uploading batch-data/45.csv\n",
            "Uploaded batch-data/45.csv, 41 files out of an estimated total of 100\n",
            "Uploading batch-data/46.csv\n",
            "Uploaded batch-data/46.csv, 42 files out of an estimated total of 100\n",
            "Uploading batch-data/47.csv\n",
            "Uploaded batch-data/47.csv, 43 files out of an estimated total of 100\n",
            "Uploading batch-data/48.csv\n",
            "Uploaded batch-data/48.csv, 44 files out of an estimated total of 100\n",
            "Uploading batch-data/49.csv\n",
            "Uploaded batch-data/49.csv, 45 files out of an estimated total of 100\n",
            "Uploading batch-data/5.csv\n",
            "Uploaded batch-data/5.csv, 46 files out of an estimated total of 100\n",
            "Uploading batch-data/50.csv\n",
            "Uploaded batch-data/50.csv, 47 files out of an estimated total of 100\n",
            "Uploading batch-data/53.csv\n",
            "Uploaded batch-data/53.csv, 48 files out of an estimated total of 100\n",
            "Uploading batch-data/58.csv\n",
            "Uploaded batch-data/58.csv, 49 files out of an estimated total of 100\n",
            "Uploading batch-data/60.csv\n",
            "Uploaded batch-data/60.csv, 50 files out of an estimated total of 100\n",
            "Uploading batch-data/63.csv\n",
            "Uploaded batch-data/63.csv, 51 files out of an estimated total of 100\n",
            "Uploading batch-data/64.csv\n",
            "Uploaded batch-data/64.csv, 52 files out of an estimated total of 100\n",
            "Uploading batch-data/65.csv\n",
            "Uploaded batch-data/65.csv, 53 files out of an estimated total of 100\n",
            "Uploading batch-data/66.csv\n",
            "Uploaded batch-data/66.csv, 54 files out of an estimated total of 100\n",
            "Uploading batch-data/67.csv\n",
            "Uploaded batch-data/67.csv, 55 files out of an estimated total of 100\n",
            "Uploading batch-data/51.csv\n",
            "Uploaded batch-data/51.csv, 56 files out of an estimated total of 100\n",
            "Uploading batch-data/52.csv\n",
            "Uploaded batch-data/52.csv, 57 files out of an estimated total of 100\n",
            "Uploading batch-data/54.csv\n",
            "Uploaded batch-data/54.csv, 58 files out of an estimated total of 100\n",
            "Uploading batch-data/55.csv\n",
            "Uploaded batch-data/55.csv, 59 files out of an estimated total of 100\n",
            "Uploading batch-data/56.csv\n",
            "Uploaded batch-data/56.csv, 60 files out of an estimated total of 100\n",
            "Uploading batch-data/57.csv\n",
            "Uploaded batch-data/57.csv, 61 files out of an estimated total of 100\n",
            "Uploading batch-data/59.csv\n",
            "Uploaded batch-data/59.csv, 62 files out of an estimated total of 100\n",
            "Uploading batch-data/6.csv\n",
            "Uploaded batch-data/6.csv, 63 files out of an estimated total of 100\n",
            "Uploading batch-data/61.csv\n",
            "Uploaded batch-data/61.csv, 64 files out of an estimated total of 100\n",
            "Uploading batch-data/62.csv\n",
            "Uploaded batch-data/62.csv, 65 files out of an estimated total of 100\n",
            "Uploading batch-data/68.csv\n",
            "Uploaded batch-data/68.csv, 66 files out of an estimated total of 100\n",
            "Uploading batch-data/69.csv\n",
            "Uploaded batch-data/69.csv, 67 files out of an estimated total of 100\n",
            "Uploading batch-data/7.csv\n",
            "Uploaded batch-data/7.csv, 68 files out of an estimated total of 100\n",
            "Uploading batch-data/70.csv\n",
            "Uploaded batch-data/70.csv, 69 files out of an estimated total of 100\n",
            "Uploading batch-data/71.csv\n",
            "Uploaded batch-data/71.csv, 70 files out of an estimated total of 100\n",
            "Uploading batch-data/72.csv\n",
            "Uploaded batch-data/72.csv, 71 files out of an estimated total of 100\n",
            "Uploading batch-data/73.csv\n",
            "Uploaded batch-data/73.csv, 72 files out of an estimated total of 100\n",
            "Uploading batch-data/74.csv\n",
            "Uploaded batch-data/74.csv, 73 files out of an estimated total of 100\n",
            "Uploading batch-data/75.csv\n",
            "Uploaded batch-data/75.csv, 74 files out of an estimated total of 100\n",
            "Uploading batch-data/76.csv\n",
            "Uploaded batch-data/76.csv, 75 files out of an estimated total of 100\n",
            "Uploading batch-data/77.csv\n",
            "Uploaded batch-data/77.csv, 76 files out of an estimated total of 100\n",
            "Uploading batch-data/78.csv\n",
            "Uploaded batch-data/78.csv, 77 files out of an estimated total of 100\n",
            "Uploading batch-data/79.csv\n",
            "Uploaded batch-data/79.csv, 78 files out of an estimated total of 100\n",
            "Uploading batch-data/8.csv\n",
            "Uploaded batch-data/8.csv, 79 files out of an estimated total of 100\n",
            "Uploading batch-data/80.csv\n",
            "Uploaded batch-data/80.csv, 80 files out of an estimated total of 100\n",
            "Uploading batch-data/81.csv\n",
            "Uploaded batch-data/81.csv, 81 files out of an estimated total of 100\n",
            "Uploading batch-data/82.csv\n",
            "Uploaded batch-data/82.csv, 82 files out of an estimated total of 100\n",
            "Uploading batch-data/83.csv\n",
            "Uploaded batch-data/83.csv, 83 files out of an estimated total of 100\n",
            "Uploading batch-data/84.csv\n",
            "Uploaded batch-data/84.csv, 84 files out of an estimated total of 100\n",
            "Uploading batch-data/85.csv\n",
            "Uploaded batch-data/85.csv, 85 files out of an estimated total of 100\n",
            "Uploading batch-data/86.csv\n",
            "Uploaded batch-data/86.csv, 86 files out of an estimated total of 100\n",
            "Uploading batch-data/87.csv\n",
            "Uploaded batch-data/87.csv, 87 files out of an estimated total of 100\n",
            "Uploading batch-data/88.csv\n",
            "Uploaded batch-data/88.csv, 88 files out of an estimated total of 100\n",
            "Uploading batch-data/89.csv\n",
            "Uploaded batch-data/89.csv, 89 files out of an estimated total of 100\n",
            "Uploading batch-data/9.csv\n",
            "Uploaded batch-data/9.csv, 90 files out of an estimated total of 100\n",
            "Uploading batch-data/90.csv\n",
            "Uploaded batch-data/90.csv, 91 files out of an estimated total of 100\n",
            "Uploading batch-data/91.csv\n",
            "Uploaded batch-data/91.csv, 92 files out of an estimated total of 100\n",
            "Uploading batch-data/92.csv\n",
            "Uploaded batch-data/92.csv, 93 files out of an estimated total of 100\n",
            "Uploading batch-data/93.csv\n",
            "Uploaded batch-data/93.csv, 94 files out of an estimated total of 100\n",
            "Uploading batch-data/94.csv\n",
            "Uploaded batch-data/94.csv, 95 files out of an estimated total of 100\n",
            "Uploading batch-data/95.csv\n",
            "Uploaded batch-data/95.csv, 96 files out of an estimated total of 100\n",
            "Uploading batch-data/96.csv\n",
            "Uploaded batch-data/96.csv, 97 files out of an estimated total of 100\n",
            "Uploading batch-data/97.csv\n",
            "Uploaded batch-data/97.csv, 98 files out of an estimated total of 100\n",
            "Uploading batch-data/98.csv\n",
            "Uploaded batch-data/98.csv, 99 files out of an estimated total of 100\n",
            "Uploading batch-data/99.csv\n",
            "Uploaded batch-data/99.csv, 100 files out of an estimated total of 100\n",
            "Uploaded 100 files\n",
            "Done!\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1621437610190
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create compute\n",
        "\n",
        "We'll need a compute context for the pipeline, so we'll use the following code to specify an Azure Machine Learning compute cluster (it will be created if it doesn't already exist).\n",
        "\n",
        "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"art-cluster-2\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        inference_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1621439544340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a pipeline for batch inferencing\n",
        "\n",
        "Now we're ready to define the pipeline we'll use for batch inferencing. Our pipeline will need Python code to perform the batch inferencing, so let's create a folder where we can keep all the files used by the pipeline:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'batch_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_pipeline\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1621437666433
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create a Python script to do the actual work, and save it in the pipeline folder:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/batch_diabetes.py\n",
        "import os\n",
        "import numpy as np\n",
        "from azureml.core import Model\n",
        "import joblib\n",
        "\n",
        "\n",
        "def init():\n",
        "    # Runs when the pipeline step is initialized\n",
        "    global model\n",
        "\n",
        "    # load the model\n",
        "    model_path = Model.get_model_path('diabetes_model')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "\n",
        "def run(mini_batch):\n",
        "    # This runs for each batch\n",
        "    resultList = []\n",
        "\n",
        "    # process each file in the batch\n",
        "    for f in mini_batch:\n",
        "        # Read the comma-delimited data into an array\n",
        "        data = np.genfromtxt(f, delimiter=',')\n",
        "        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\n",
        "        prediction = model.predict(data.reshape(1, -1))\n",
        "        # Append prediction to results\n",
        "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\n",
        "    return resultList"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing batch_pipeline/batch_diabetes.py\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll define a run context that includes the dependencies required by the script"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
        "from azureml.core.runconfig import CondaDependencies\n",
        "\n",
        "# Add dependencies required by the model\n",
        "# For scikit-learn models, you need scikit-learn\n",
        "# For parallel pipeline steps, you need azureml-core and azureml-dataprep[fuse]\n",
        "cd = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n",
        "                              pip_packages=['azureml-defaults','azureml-core','azureml-dataprep[fuse]'])\n",
        "\n",
        "batch_env = Environment(name='batch_environment')\n",
        "batch_env.python.conda_dependencies = cd\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
        "print('Configuration ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration ready.\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1621437766700
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a **ParallelRunStep**, which enables the batch data to be processed in parallel and the results collated in a single output file named *parallel_run_step.txt*.\n",
        "\n",
        "> **Note**: An *'enabled' is deprecated* warning may be displayed - you can ignore this."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
        "from azureml.pipeline.core import PipelineData\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "output_dir = PipelineData(name='inferences', \n",
        "                          datastore=default_ds, \n",
        "                          output_path_on_compute='diabetes/results')\n",
        "\n",
        "parallel_run_config = ParallelRunConfig(\n",
        "    source_directory=experiment_folder,\n",
        "    entry_script=\"batch_diabetes.py\",\n",
        "    mini_batch_size=\"5\",\n",
        "    error_threshold=10,\n",
        "    output_action=\"append_row\",\n",
        "    environment=batch_env,\n",
        "    compute_target=inference_cluster,\n",
        "    node_count=2)\n",
        "\n",
        "parallelrun_step = ParallelRunStep(\n",
        "    name='batch-score-diabetes',\n",
        "    parallel_run_config=parallel_run_config,\n",
        "    inputs=[batch_data_set.as_named_input('diabetes_batch')],\n",
        "    output=output_dir,\n",
        "    arguments=[],\n",
        "    allow_reuse=True\n",
        ")\n",
        "\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps defined\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1621439553333
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to put the step into a pipeline, and run it.\n",
        "\n",
        "> **Note**: This may take some time!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "\n",
        "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
        "pipeline_run = Experiment(ws, 'mslearn-diabetes-batch').submit(pipeline)\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created step batch-score-diabetes [94eac006][23364924-f811-4968-bb99-1a8490d297b5], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun e779e5a5-00bb-4ca6-a471-fb2b05605021\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/e779e5a5-00bb-4ca6-a471-fb2b05605021?wsid=/subscriptions/560f88cc-c40a-468a-81b5-2453d57e1da9/resourcegroups/art-ml-oneweek/workspaces/oneweek&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "PipelineRunId: e779e5a5-00bb-4ca6-a471-fb2b05605021\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/e779e5a5-00bb-4ca6-a471-fb2b05605021?wsid=/subscriptions/560f88cc-c40a-468a-81b5-2453d57e1da9/resourcegroups/art-ml-oneweek/workspaces/oneweek&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "PipelineRun Status: NotStarted\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 379ec713-f2b0-4fcb-8e2d-cdde539a94ad\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/379ec713-f2b0-4fcb-8e2d-cdde539a94ad?wsid=/subscriptions/560f88cc-c40a-468a-81b5-2453d57e1da9/resourcegroups/art-ml-oneweek/workspaces/oneweek&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "StepRun( batch-score-diabetes ) Status: NotStarted\n",
            "StepRun( batch-score-diabetes ) Status: Queued\n",
            "StepRun( batch-score-diabetes ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/20_image_build_log.txt\n",
            "=============================================\n",
            "2021/05/19 15:53:58 Downloading source code...\n",
            "2021/05/19 15:53:59 Finished downloading source code\n",
            "2021/05/19 15:54:00 Creating Docker network: acb_default_network, driver: 'bridge'\n",
            "2021/05/19 15:54:01 Successfully set up Docker network: acb_default_network\n",
            "2021/05/19 15:54:01 Setting up Docker configuration...\n",
            "2021/05/19 15:54:01 Successfully set up Docker configuration\n",
            "2021/05/19 15:54:01 Logging in to registry: 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io\n",
            "2021/05/19 15:54:03 Successfully logged into 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io\n",
            "2021/05/19 15:54:03 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/05/19 15:54:03 Scanning for dependencies...\n",
            "2021/05/19 15:54:03 Successfully scanned dependencies\n",
            "2021/05/19 15:54:03 Launching container with name: acb_step_0\n",
            "Sending build context to Docker daemon  66.56kB\n",
            "\n",
            "\n",
            "Step 1/18 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
            "Digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1@sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            " ---> c942df5ba5d0\n",
            "Step 2/18 : USER root\n",
            " ---> Running in 2b38ba5942df\n",
            "Removing intermediate container 2b38ba5942df\n",
            " ---> c3c718e82132\n",
            "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
            " ---> Running in cdfd7b6d4767\n",
            "Removing intermediate container cdfd7b6d4767\n",
            " ---> 679f39f6b1e4\n",
            "Step 4/18 : WORKDIR /\n",
            " ---> Running in 605bd039a3f7\n",
            "Removing intermediate container 605bd039a3f7\n",
            " ---> 24f06125e065\n",
            "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
            " ---> 808874bb87c4\n",
            "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
            " ---> Running in fe967d91ffc7\n",
            "Removing intermediate container fe967d91ffc7\n",
            " ---> 89d3656f36d1\n",
            "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
            " ---> 9601ac620db1\n",
            "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
            " ---> Running in 153c8eb442f7\n",
            "Collecting package metadata (repodata.json): ...working... \n",
            "done\n",
            "Solving environment: ...working... \n",
            "done\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "setuptools-50.3.0    | 891 KB    |            |   0% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "\n",
            "six-1.15.0           | 13 KB     |            |   0% \n",
            "six-1.15.0           | 13 KB     | ########## | 100% \n",
            "\n",
            "pip-20.2.4           | 2.0 MB    |            |   0% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "\n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "\n",
            "scikit-learn-0.23.2  | 6.9 MB    |            |   0% \n",
            "scikit-learn-0.23.2  | 6.9 MB    | ########2  |  82% \n",
            "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
            "\n",
            "zlib-1.2.11          | 120 KB    |            |   0% \n",
            "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
            "\n",
            "joblib-0.17.0        | 205 KB    |            |   0% \n",
            "joblib-0.17.0        | 205 KB    | ########## | 100% \n",
            "\n",
            "readline-7.0         | 387 KB    |            |   0% \n",
            "readline-7.0         | 387 KB    | ########## | 100% \n",
            "readline-7.0         | 387 KB    | ########## | 100% \n",
            "\n",
            "wheel-0.35.1         | 36 KB     |            |   0% \n",
            "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
            "\n",
            "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \n",
            "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
            "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
            "\n",
            "intel-openmp-2020.2  | 947 KB    |            |   0% \n",
            "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
            "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
            "\n",
            "ca-certificates-2020 | 128 KB    |            |   0% \n",
            "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
            "\n",
            "numpy-base-1.19.1    | 5.2 MB    |            |   0% \n",
            "numpy-base-1.19.1    | 5.2 MB    | ########4  |  84% \n",
            "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
            "\n",
            "xz-5.2.5             | 438 KB    |            |   0% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "\n",
            "blas-1.0             | 6 KB      |            |   0% \n",
            "blas-1.0             | 6 KB      | ########## | 100% \n",
            "\n",
            "mkl_random-1.1.0     | 369 KB    |            |   0% \n",
            "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
            "\n",
            "tk-8.6.10            | 3.2 MB    |            |   0% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "\n",
            "libedit-3.1          | 171 KB    |            |   0% \n",
            "libedit-3.1          | 171 KB    | ########## | 100% \n",
            "\n",
            "libffi-3.2.1         | 52 KB     |            |   0% \n",
            "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
            "\n",
            "ncurses-6.0          | 907 KB    |            |   0% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "\n",
            "mkl_fft-1.2.0        | 164 KB    |            |   0% \n",
            "mkl_fft-1.2.0        | 164 KB    | ########## | 100% \n",
            "\n",
            "mkl-service-2.3.0    | 208 KB    |            |   0% \n",
            "mkl-service-2.3.0    | 208 KB    | ########## | 100% \n",
            "\n",
            "scipy-1.5.2          | 18.5 MB   |            |   0% \n",
            "scipy-1.5.2          | 18.5 MB   | ###2       |  33% \n",
            "scipy-1.5.2          | 18.5 MB   | #######8   |  79% \n",
            "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
            "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
            "\n",
            "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
            "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
            "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
            "\n",
            "python-3.6.2         | 27.0 MB   |            |   0% \n",
            "python-3.6.2         | 27.0 MB   | 7          |   8% \n",
            "python-3.6.2         | 27.0 MB   | ###7       |  37% \n",
            "python-3.6.2         | 27.0 MB   | ######6    |  67% \n",
            "python-3.6.2         | 27.0 MB   | #########8 |  98% \n",
            "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
            "\n",
            "mkl-2019.4           | 204.1 MB  |            |   0% \n",
            "mkl-2019.4           | 204.1 MB  | 1          |   2% \n",
            "mkl-2019.4           | 204.1 MB  | 5          |   5% \n",
            "mkl-2019.4           | 204.1 MB  | 9          |   9% \n",
            "mkl-2019.4           | 204.1 MB  | #1         |  12% \n",
            "mkl-2019.4           | 204.1 MB  | #4         |  15% \n",
            "mkl-2019.4           | 204.1 MB  | #8         |  18% \n",
            "mkl-2019.4           | 204.1 MB  | ##2        |  22% \n",
            "mkl-2019.4           | 204.1 MB  | ##6        |  26% \n",
            "mkl-2019.4           | 204.1 MB  | ###        |  30% \n",
            "mkl-2019.4           | 204.1 MB  | ###4       |  35% \n",
            "mkl-2019.4           | 204.1 MB  | ###8       |  39% \n",
            "mkl-2019.4           | 204.1 MB  | ####2      |  43% \n",
            "mkl-2019.4           | 204.1 MB  | ####6      |  46% \n",
            "mkl-2019.4           | 204.1 MB  | #####      |  50% \n",
            "mkl-2019.4           | 204.1 MB  | #####4     |  54% \n",
            "mkl-2019.4           | 204.1 MB  | #####8     |  59% \n",
            "mkl-2019.4           | 204.1 MB  | ######2    |  63% \n",
            "mkl-2019.4           | 204.1 MB  | ######6    |  67% \n",
            "mkl-2019.4           | 204.1 MB  | #######1   |  71% \n",
            "mkl-2019.4           | 204.1 MB  | #######5   |  75% \n",
            "mkl-2019.4           | 204.1 MB  | #######9   |  79% \n",
            "mkl-2019.4           | 204.1 MB  | ########3  |  83% \n",
            "mkl-2019.4           | 204.1 MB  | ########6  |  87% \n",
            "mkl-2019.4           | 204.1 MB  | #########1 |  91% \n",
            "mkl-2019.4           | 204.1 MB  | #########5 |  95% \n",
            "mkl-2019.4           | 204.1 MB  | #########8 |  99% \n",
            "\n",
            "mkl-2019.4           | 204.1 MB  | ########## | 100% \n",
            "\n",
            "certifi-2020.6.20    | 160 KB    |            |   0% \n",
            "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
            "\n",
            "numpy-1.19.1         | 20 KB     |            |   0% \n",
            "numpy-1.19.1         | 20 KB     | ########## | 100% \n",
            "\n",
            "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | #######1   |  72% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
            "\n",
            "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "\n",
            "threadpoolctl-2.1.0  | 16 KB     |            |   0% \n",
            "threadpoolctl-2.1.0  | 16 KB     | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Installing pip dependencies: ...working... \n",
            "Ran pip subprocess with arguments:\n",
            "['/azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.e56qnf1l.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Collecting azureml-defaults~=1.27.0\n",
            "  Downloading azureml_defaults-1.27.0-py3-none-any.whl (3.1 kB)\n",
            "Collecting azureml-core~=1.27.0\n",
            "  Downloading azureml_core-1.27.0-py3-none-any.whl (2.2 MB)\n",
            "Collecting azureml-dataprep[fuse]\n",
            "  Downloading azureml_dataprep-2.16.0-py3-none-any.whl (39.4 MB)\n",
            "Collecting flask==1.0.3\n",
            "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
            "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
            "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
            "Collecting applicationinsights>=0.11.7\n",
            "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
            "Collecting gunicorn==19.9.0\n",
            "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
            "Collecting azureml-dataset-runtime[fuse]~=1.27.0\n",
            "  Downloading azureml_dataset_runtime-1.27.0-py3-none-any.whl (3.4 kB)\n",
            "Collecting json-logging-py==0.2\n",
            "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
            "Collecting werkzeug<=1.0.1,>=0.16.1\n",
            "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
            "Collecting configparser==3.7.4\n",
            "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "Collecting urllib3>=1.23\n",
            "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
            "Collecting python-dateutil<3.0.0,>=2.7.3\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "Collecting azure-mgmt-containerregistry>=2.0.0\n",
            "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
            "Collecting jsonpickle<3.0.0\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting azure-common<2.0.0,>=1.1.12\n",
            "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
            "Collecting pytz\n",
            "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
            "Collecting adal>=1.2.0\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "Collecting pyopenssl<21.0.0\n",
            "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
            "Collecting contextlib2<1.0.0\n",
            "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting docker<5.0.0\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "Collecting SecretStorage<4.0.0\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting requests<3.0.0,>=2.19.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "Collecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
            "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
            "Collecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
            "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
            "  Downloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Collecting pathspec<1.0.0\n",
            "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting msrest<1.0.0,>=0.5.1\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "Collecting ruamel.yaml<1.0.0,>=0.15.35\n",
            "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "Collecting ndg-httpsclient\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting msrestazure>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
            "Collecting jmespath<1.0.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting azureml-dataprep-native<35.0.0,>=34.0.0\n",
            "  Downloading azureml_dataprep_native-34.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
            "Collecting cloudpickle<2.0.0,>=1.1.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting azure-identity<1.5.0,>=1.2.0\n",
            "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
            "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
            "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
            "Collecting azureml-dataprep-rslex<1.15.0a,>=1.14.0dev0\n",
            "  Downloading azureml_dataprep_rslex-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (9.9 MB)\n",
            "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "Collecting itsdangerous>=0.24\n",
            "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
            "Collecting Jinja2>=2.10\n",
            "  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
            "Collecting click>=5.1\n",
            "  Downloading click-8.0.0-py3-none-any.whl (96 kB)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10 in /azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.27.0->-r /azureml-environment-setup/condaenv.e56qnf1l.requirements.txt (line 1)) (1.15.0)\n",
            "Collecting liac-arff>=2.1.1\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.0 in /azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.27.0->-r /azureml-environment-setup/condaenv.e56qnf1l.requirements.txt (line 1)) (1.19.1)\n",
            "Collecting dill>=0.2.7.1\n",
            "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
            "Collecting pandas>=0.20.2\n",
            "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
            "Collecting pyarrow<2.0.0,>=0.17.0\n",
            "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting cffi>=1.12\n",
            "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
            "Collecting importlib-metadata; python_version < \"3.8\"\n",
            "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.0.0-py2.py3-none-any.whl (68 kB)\n",
            "Collecting jeepney>=0.6\n",
            "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
            "Collecting idna<3,>=2.5\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad/lib/python3.6/site-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.27.0->-r /azureml-environment-setup/condaenv.e56qnf1l.requirements.txt (line 2)) (2020.6.20)\n",
            "Collecting chardet<5,>=3.0.2\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "Collecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting requests-oauthlib>=0.5.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
            "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
            "Collecting pyasn1>=0.1.1\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting azure-core<2.0.0,>=1.0.0\n",
            "  Downloading azure_core-1.14.0-py2.py3-none-any.whl (136 kB)\n",
            "Collecting msal-extensions~=0.2.2\n",
            "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting msal<2.0.0,>=1.3.0\n",
            "  Downloading msal-1.11.0-py2.py3-none-any.whl (63 kB)\n",
            "Collecting distro>=1.2.0\n",
            "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (30 kB)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
            "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
            "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
            "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: json-logging-py, fusepy, liac-arff\n",
            "  Building wheel for json-logging-py (setup.py): started\n",
            "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
            "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=96f07101990f0ac16ce7943803e3e164d7679d2b45bc8461e5860ec393cdd7be\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
            "  Building wheel for fusepy (setup.py): started\n",
            "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=be9e0e158d291d3e107c6075e790ae200813355e3e04709ba52c840ec596882f\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
            "  Building wheel for liac-arff (setup.py): started\n",
            "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=c550b92ab55e24f00d1558dc44e738526936100d864ac8e8430d61b3375329c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
            "Successfully built json-logging-py fusepy liac-arff\n",
            "Installing collected packages: werkzeug, itsdangerous, MarkupSafe, Jinja2, click, flask, pycparser, cffi, cryptography, PyJWT, idna, urllib3, chardet, requests, python-dateutil, adal, liac-arff, dill, pytz, pandas, azureml-model-management-sdk, applicationinsights, gunicorn, azure-common, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-mgmt-containerregistry, azure-mgmt-authorization, typing-extensions, zipp, importlib-metadata, jsonpickle, pyopenssl, contextlib2, websocket-client, docker, jeepney, SecretStorage, backports.weakref, backports.tempfile, azure-mgmt-storage, azure-mgmt-resource, pathspec, ruamel.yaml.clib, ruamel.yaml, azure-graphrbac, pyasn1, ndg-httpsclient, azure-mgmt-keyvault, jmespath, azureml-core, pyarrow, azureml-dataprep-native, cloudpickle, azure-core, portalocker, msal, msal-extensions, azure-identity, distro, dotnetcore2, azureml-dataprep-rslex, fusepy, azureml-dataprep, azureml-dataset-runtime, json-logging-py, configparser, azureml-defaults\n",
            "Successfully installed Jinja2-3.0.1 MarkupSafe-2.0.1 PyJWT-2.1.0 SecretStorage-3.3.1 adal-1.2.7 applicationinsights-0.11.10 azure-common-1.1.27 azure-core-1.14.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-13.0.0 azure-mgmt-storage-11.2.0 azureml-core-1.27.0 azureml-dataprep-2.16.0 azureml-dataprep-native-34.0.0 azureml-dataprep-rslex-1.14.0 azureml-dataset-runtime-1.27.0 azureml-defaults-1.27.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.5 chardet-4.0.0 click-8.0.0 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.4.7 dill-0.3.3 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.20 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-4.0.1 isodate-0.6.0 itsdangerous-2.0.1 jeepney-0.6.0 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.0.0 liac-arff-2.5.0 msal-1.11.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.0 pandas-1.1.5 pathspec-0.8.1 portalocker-1.7.1 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 python-dateutil-2.8.1 pytz-2021.1 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 typing-extensions-3.10.0.0 urllib3-1.26.4 websocket-client-1.0.0 werkzeug-1.0.1 zipp-3.4.1\n",
            "\u001b[91m\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.9.2\n",
            "  latest version: 4.10.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "done\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "WARNING: /root/.conda/pkgs does not exist\n",
            "Removing intermediate container 153c8eb442f7\n",
            " ---> 149362ae39df\n",
            "Step 9/18 : ENV PATH /azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad/bin:$PATH\n",
            " ---> Running in 88721816592c\n",
            "Removing intermediate container 88721816592c\n",
            " ---> 63685a3faa5e\n",
            "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
            " ---> 8668b4e1c516\n",
            "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
            " ---> f957b9b506ba\n",
            "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad\n",
            " ---> Running in c7f6377290b9\n",
            "Report materialized dependencies for the environment\n",
            "Reading environment context\n",
            "Exporting conda environment\n",
            "Sending request with materialized conda environment details\n",
            "Successfully sent materialized environment details\n",
            "Removing intermediate container c7f6377290b9\n",
            " ---> ce329332022a\n",
            "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad\n",
            " ---> Running in d5ff978c5f59\n",
            "Removing intermediate container d5ff978c5f59\n",
            " ---> d540e8ab7f59\n",
            "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_aa77a7252d8f04306986f9fa8a3997ad/lib:$LD_LIBRARY_PATH\n",
            " ---> Running in 81c8088ac04c\n",
            "Removing intermediate container 81c8088ac04c\n",
            " ---> 2a0cfc9b0133\n",
            "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
            " ---> 652484208a27\n",
            "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
            " ---> Running in d48db25bb95c\n",
            "Removing intermediate container d48db25bb95c\n",
            " ---> e42f9898c725\n",
            "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
            " ---> Running in 306a5b3619e9\n",
            "Removing intermediate container 306a5b3619e9\n",
            " ---> 172abb55cb47\n",
            "Step 18/18 : CMD [\"bash\"]\n",
            " ---> Running in 569aac4c0699\n",
            "Removing intermediate container 569aac4c0699\n",
            " ---> dc85153bbb5b\n",
            "Successfully built dc85153bbb5b\n",
            "Successfully tagged 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io/azureml/azureml_30f73517ee346cfd8e80806a4c9e074e:latest\n",
            "Successfully tagged 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io/azureml/azureml_30f73517ee346cfd8e80806a4c9e074e:1\n",
            "2021/05/19 15:58:18 Successfully executed container: acb_step_0\n",
            "2021/05/19 15:58:18 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/05/19 15:58:18 Pushing image: 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io/azureml/azureml_30f73517ee346cfd8e80806a4c9e074e:1, attempt 1\n",
            "The push refers to repository [215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io/azureml/azureml_30f73517ee346cfd8e80806a4c9e074e]\n",
            "de9c3ce87a41: Preparing\n",
            "03f2271545df: Preparing\n",
            "350e2fd0cef6: Preparing\n",
            "d26528bcfa8d: Preparing\n",
            "ed56f82d3f97: Preparing\n",
            "d1f7aead4a57: Preparing\n",
            "1b4ffcb2a562: Preparing\n",
            "48ec8709685f: Preparing\n",
            "3a883b8dff6b: Preparing\n",
            "3f3f8889d538: Preparing\n",
            "420340de7040: Preparing\n",
            "c3d9b0d7dd4c: Preparing\n",
            "4441896e1280: Preparing\n",
            "a64fe594a899: Preparing\n",
            "0d34930f20d5: Preparing\n",
            "18c9012f327d: Preparing\n",
            "e4a0bf630548: Preparing\n",
            "5276d2b930fc: Preparing\n",
            "e6feec0db89a: Preparing\n",
            "697949baa658: Preparing\n",
            "935c56d8b3f9: Preparing\n",
            "c3d9b0d7dd4c: Waiting\n",
            "4441896e1280: Waiting\n",
            "a64fe594a899: Waiting\n",
            "0d34930f20d5: Waiting\n",
            "18c9012f327d: Waiting\n",
            "e4a0bf630548: Waiting\n",
            "5276d2b930fc: Waiting\n",
            "e6feec0db89a: Waiting\n",
            "697949baa658: Waiting\n",
            "935c56d8b3f9: Waiting\n",
            "d1f7aead4a57: Waiting\n",
            "1b4ffcb2a562: Waiting\n",
            "48ec8709685f: Waiting\n",
            "3a883b8dff6b: Waiting\n",
            "3f3f8889d538: Waiting\n",
            "420340de7040: Waiting\n",
            "d26528bcfa8d: Pushed\n",
            "de9c3ce87a41: Pushed\n",
            "350e2fd0cef6: Pushed\n",
            "03f2271545df: Pushed\n",
            "d1f7aead4a57: Pushed\n",
            "1b4ffcb2a562: Pushed\n",
            "48ec8709685f: Pushed\n",
            "3a883b8dff6b: Pushed\n",
            "3f3f8889d538: Pushed\n",
            "420340de7040: Pushed\n",
            "c3d9b0d7dd4c: Pushed\n",
            "18c9012f327d: Pushed\n",
            "4441896e1280: Pushed\n",
            "a64fe594a899: Pushed\n",
            "5276d2b930fc: Pushed\n",
            "e6feec0db89a: Pushed\n",
            "697949baa658: Pushed\n",
            "0d34930f20d5: Pushed\n",
            "\n",
            "935c56d8b3f9: Pushed\n",
            "e4a0bf630548: Pushed\n",
            "ed56f82d3f97: Pushed\n",
            "1: digest: sha256:8b9eccbaba0382c1e49b141ce34ee644fd2dc1379a1c4b5c8021dd0ef7580ebb size: 4721\n",
            "2021/05/19 16:00:46 Successfully pushed image: 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io/azureml/azureml_30f73517ee346cfd8e80806a4c9e074e:1\n",
            "2021/05/19 16:00:46 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/05/19 16:00:46 Pushing image: 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io/azureml/azureml_30f73517ee346cfd8e80806a4c9e074e:latest, attempt 1\n",
            "The push refers to repository [215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io/azureml/azureml_30f73517ee346cfd8e80806a4c9e074e]\n",
            "de9c3ce87a41: Preparing\n",
            "03f2271545df: Preparing\n",
            "350e2fd0cef6: Preparing\n",
            "d26528bcfa8d: Preparing\n",
            "ed56f82d3f97: Preparing\n",
            "d1f7aead4a57: Preparing\n",
            "1b4ffcb2a562: Preparing\n",
            "48ec8709685f: Preparing\n",
            "3a883b8dff6b: Preparing\n",
            "3f3f8889d538: Preparing\n",
            "420340de7040: Preparing\n",
            "c3d9b0d7dd4c: Preparing\n",
            "4441896e1280: Preparing\n",
            "a64fe594a899: Preparing\n",
            "0d34930f20d5: Preparing\n",
            "18c9012f327d: Preparing\n",
            "e4a0bf630548: Preparing\n",
            "5276d2b930fc: Preparing\n",
            "e6feec0db89a: Preparing\n",
            "697949baa658: Preparing\n",
            "935c56d8b3f9: Preparing\n",
            "d1f7aead4a57: Waiting\n",
            "1b4ffcb2a562: Waiting\n",
            "48ec8709685f: Waiting\n",
            "3a883b8dff6b: Waiting\n",
            "3f3f8889d538: Waiting\n",
            "420340de7040: Waiting\n",
            "c3d9b0d7dd4c: Waiting\n",
            "4441896e1280: Waiting\n",
            "a64fe594a899: Waiting\n",
            "0d34930f20d5: Waiting\n",
            "18c9012f327d: Waiting\n",
            "e4a0bf630548: Waiting\n",
            "5276d2b930fc: Waiting\n",
            "e6feec0db89a: Waiting\n",
            "697949baa658: Waiting\n",
            "935c56d8b3f9: Waiting\n",
            "de9c3ce87a41: Layer already exists\n",
            "ed56f82d3f97: Layer already exists\n",
            "03f2271545df: Layer already exists\n",
            "d26528bcfa8d: Layer already exists\n",
            "350e2fd0cef6: Layer already exists\n",
            "d1f7aead4a57: Layer already exists\n",
            "48ec8709685f: Layer already exists\n",
            "420340de7040: Layer already exists\n",
            "1b4ffcb2a562: Layer already exists\n",
            "3a883b8dff6b: Layer already exists\n",
            "3f3f8889d538: Layer already exists\n",
            "c3d9b0d7dd4c: Layer already exists\n",
            "4441896e1280: Layer already exists\n",
            "a64fe594a899: Layer already exists\n",
            "18c9012f327d: Layer already exists\n",
            "e4a0bf630548: Layer already exists\n",
            "0d34930f20d5: Layer already exists\n",
            "5276d2b930fc: Layer already exists\n",
            "e6feec0db89a: Layer already exists\n",
            "935c56d8b3f9: Layer already exists\n",
            "697949baa658: Layer already exists\n",
            "latest: digest: sha256:8b9eccbaba0382c1e49b141ce34ee644fd2dc1379a1c4b5c8021dd0ef7580ebb size: 4721\n",
            "2021/05/19 16:00:53 Successfully pushed image: 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io/azureml/azureml_30f73517ee346cfd8e80806a4c9e074e:latest\n",
            "2021/05/19 16:00:53 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 255.564799)\n",
            "2021/05/19 16:00:53 Populating digests for step ID: acb_step_0...\n",
            "2021/05/19 16:00:59 Successfully populated digests for step ID: acb_step_0\n",
            "2021/05/19 16:00:59 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 147.996583)\n",
            "2021/05/19 16:00:59 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 6.674336)\n",
            "2021/05/19 16:00:59 The following dependencies were found:\n",
            "2021/05/19 16:00:59 \n",
            "- image:\n",
            "    registry: 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io\n",
            "    repository: azureml/azureml_30f73517ee346cfd8e80806a4c9e074e\n",
            "    tag: latest\n",
            "    digest: sha256:8b9eccbaba0382c1e49b141ce34ee644fd2dc1379a1c4b5c8021dd0ef7580ebb\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
            "    tag: 20210301.v1\n",
            "    digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "  git: {}\n",
            "- image:\n",
            "    registry: 215cb2c08e234b1cb1ec714c5f035f7a.azurecr.io\n",
            "    repository: azureml/azureml_30f73517ee346cfd8e80806a4c9e074e\n",
            "    tag: \"1\"\n",
            "    digest: sha256:8b9eccbaba0382c1e49b141ce34ee644fd2dc1379a1c4b5c8021dd0ef7580ebb\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
            "    tag: 20210301.v1\n",
            "    digest: sha256:000d6c43f606ceaa67983790ca95c70fd741c364d8c2e3217a11d775b99741df\n",
            "  git: {}\n",
            "\n",
            "Run ID: ca1 was successful after 7m2s\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt\n",
            "========================================================================================================================\n",
            "2021-05-19T16:01:25Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/mounts/workspaceblobstore\n",
            "2021-05-19T16:01:26Z Starting output-watcher...\n",
            "2021-05-19T16:01:26Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_4539de3ccb169db6707c8cade7afe14c\n",
            "4007a89234b4: Pulling fs layer\n",
            "5dfa26c6b9c9: Pulling fs layer\n",
            "0ba7bf18aa40: Pulling fs layer\n",
            "4c6ec688ebe3: Pulling fs layer\n",
            "574f361512d6: Pulling fs layer\n",
            "db4d1e2d7079: Pulling fs layer\n",
            "e544ee0f522d: Pulling fs layer\n",
            "c655136086be: Pulling fs layer\n",
            "2ec37f44090c: Pulling fs layer\n",
            "5fba3bd4a2c4: Pulling fs layer\n",
            "7e0ea9d0a1ab: Pulling fs layer\n",
            "da005f826951: Pulling fs layer\n",
            "ac4e1c91b241: Pulling fs layer\n",
            "efb648489c68: Pulling fs layer\n",
            "e5e2bb35fef1: Pulling fs layer\n",
            "41f64f9d12ca: Pulling fs layer\n",
            "404e390f8ac9: Pulling fs layer\n",
            "00d1c09f699a: Pulling fs layer\n",
            "db4d1e2d7079: Waiting\n",
            "5fba3bd4a2c4: Waiting\n",
            "7e0ea9d0a1ab: Waiting\n",
            "e544ee0f522d: Waiting\n",
            "c655136086be: Waiting\n",
            "2ec37f44090c: Waiting\n",
            "4c6ec688ebe3: Waiting\n",
            "da005f826951: Waiting\n",
            "41f64f9d12ca: Waiting\n",
            "ac4e1c91b241: Waiting\n",
            "efb648489c68: Waiting\n",
            "404e390f8ac9: Waiting\n",
            "e5e2bb35fef1: Waiting\n",
            "00d1c09f699a: Waiting\n",
            "574f361512d6: Waiting\n",
            "5dfa26c6b9c9: Verifying Checksum\n",
            "5dfa26c6b9c9: Download complete\n",
            "0ba7bf18aa40: Verifying Checksum\n",
            "0ba7bf18aa40: Download complete\n",
            "4c6ec688ebe3: Verifying Checksum\n",
            "4c6ec688ebe3: Download complete\n",
            "db4d1e2d7079: Verifying Checksum\n",
            "db4d1e2d7079: Download complete\n",
            "4007a89234b4: Download complete\n",
            "e544ee0f522d: Verifying Checksum\n",
            "e544ee0f522d: Download complete\n",
            "574f361512d6: Verifying Checksum\n",
            "574f361512d6: Download complete\n",
            "5fba3bd4a2c4: Verifying Checksum\n",
            "5fba3bd4a2c4: Download complete\n",
            "2ec37f44090c: Verifying Checksum\n",
            "2ec37f44090c: Download complete\n",
            "7e0ea9d0a1ab: Verifying Checksum\n",
            "7e0ea9d0a1ab: Download complete\n",
            "da005f826951: Verifying Checksum\n",
            "da005f826951: Download complete\n",
            "ac4e1c91b241: Verifying Checksum\n",
            "ac4e1c91b241: Download complete\n",
            "e5e2bb35fef1: Download complete\n",
            "41f64f9d12ca: Verifying Checksum\n",
            "41f64f9d12ca: Download complete\n",
            "404e390f8ac9: Verifying Checksum\n",
            "404e390f8ac9: Download complete\n",
            "4007a89234b4: Pull complete\n",
            "00d1c09f699a: Verifying Checksum\n",
            "00d1c09f699a: Download complete\n",
            "5dfa26c6b9c9: Pull complete\n",
            "c655136086be: Verifying Checksum\n",
            "c655136086be: Download complete\n",
            "0ba7bf18aa40: Pull complete\n",
            "4c6ec688ebe3: Pull complete\n",
            "efb648489c68: Verifying Checksum\n",
            "efb648489c68: Download complete\n",
            "574f361512d6: Pull complete\n",
            "db4d1e2d7079: Pull complete\n",
            "e544ee0f522d: Pull complete\n",
            "c655136086be: Pull complete\n",
            "2ec37f44090c: Pull complete\n",
            "5fba3bd4a2c4: Pull complete\n",
            "7e0ea9d0a1ab: Pull complete\n",
            "da005f826951: Pull complete\n",
            "ac4e1c91b241: Pull complete\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt\n",
            "===============================================================================================================\n",
            "[2021-05-19T16:01:46.785741] Entering job preparation.\n",
            "[2021-05-19T16:01:47.459795] Starting job preparation.\n",
            "[2021-05-19T16:01:47.459847] Extracting the control code.\n",
            "[2021-05-19T16:01:47.479358] fetching and extracting the control code on master node.\n",
            "[2021-05-19T16:01:47.479408] Starting extract_project.\n",
            "[2021-05-19T16:01:47.479475] Starting to extract zip file.\n",
            "[2021-05-19T16:01:47.984579] Finished extracting zip file.\n",
            "[2021-05-19T16:01:48.279776] Using urllib.request Python 3.0 or later\n",
            "[2021-05-19T16:01:48.279838] Start fetching snapshots.\n",
            "[2021-05-19T16:01:48.279901] Start fetching snapshot.\n",
            "[2021-05-19T16:01:48.279927] Retrieving project from snapshot: 671ca28f-6ebb-4c47-badf-ea049c83fd81\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 59\n",
            "[2021-05-19T16:01:48.611458] Finished fetching snapshot.\n",
            "[2021-05-19T16:01:48.611493] Start fetching snapshot.\n",
            "[2021-05-19T16:01:48.611510] Retrieving project from snapshot: 9ac8ce02-ccb8-4993-a624-03d55a1ce322\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt\n",
            "===============================================================================================================\n",
            "[2021-05-19T16:01:49.449295] Entering job preparation.\n",
            "[2021-05-19T16:01:50.080456] Starting job preparation.\n",
            "[2021-05-19T16:01:50.080496] Extracting the control code.\n",
            "[2021-05-19T16:01:50.108643] Waiting for master node to finish fetching and extracting the control code. Will check again in 1 seconds.\n",
            "[2021-05-19T16:01:51.114096] Waiting for master node to finish fetching and extracting the control code. Will check again in 3 seconds.\n",
            "[2021-05-19T16:01:54.121501] Waiting for master node to finish fetching and extracting the control code. Will check again in 5 seconds.\n",
            "[2021-05-19T16:01:59.131174] Finished fetching and extracting the control code.\n",
            "[2021-05-19T16:01:59.131235] Not a master node. Skipping rest of the context managers.\n",
            "[2021-05-19T16:01:59.131291] Entering Data Context Managers in Sidecar\n",
            "[2021-05-19T16:01:59.132353] Running Sidecar prep cmd...\n",
            "[2021-05-19T16:01:59.647397] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/mounts/workspaceblobstore/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad\n",
            "[2021-05-19T16:01:59.648381] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
            "Enter __enter__ of DatasetContextManager\n",
            "SDK version: azureml-core==1.26.0 azureml-dataprep==2.14.2. Session id: 15152b7b-5350-483a-9bf5-fbf775b38ed8. Run id: 379ec713-f2b0-4fcb-8e2d-cdde539a94ad.\n",
            "Processing 'diabetes_batch'.\n",
            "Processing dataset FileDataset\n",
            "{\n",
            "  \"source\": [\n",
            "    \"('workspaceblobstore', 'batch-data/')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"eaa144e1-1fc2-4e2b-b611-a47e118b7e7f\",\n",
            "    \"name\": \"batch-data\",\n",
            "    \"version\": 1,\n",
            "    \"description\": \"batch data\",\n",
            "    \"workspace\": \"Workspace.create(name='oneweek', subscription_id='560f88cc-c40a-468a-81b5-2453d57e1da9', resource_group='art-ml-oneweek')\"\n",
            "  }\n",
            "}\n",
            "Mounting diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/wd/diabetes_batch_eaa144e1-1fc2-4e2b-b611-a47e118b7e7f.\n",
            "Mounted diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/wd/diabetes_batch_eaa144e1-1fc2-4e2b-b611-a47e118b7e7f as folder.\n",
            "Exit __enter__ of DatasetContextManager\n",
            "Set Dataset diabetes_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/wd/diabetes_batch_eaa144e1-1fc2-4e2b-b611-a47e118b7e7f\n",
            "Acquired lockfile /tmp/379ec713-f2b0-4fcb-8e2d-cdde539a94ad-datastore.lock to downloading input data references\n",
            "[2021-05-19T16:02:10.026142] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
            "[2021-05-19T16:02:10.870076] Ran Sidecar prep cmd.\n",
            "[2021-05-19T16:02:10.870204] Running Context Managers in Sidecar complete.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2021/05/19 16:02:36 Starting App Insight Logger for task:  runTaskLet\n",
            "2021/05/19 16:02:36 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
            "2021/05/19 16:02:36 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
            "[2021-05-19T16:02:37.006998] Entering context manager injector.\n",
            "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.27.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/mounts/workspaceblobstore/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/inferences', '--input_fds_0', 'diabetes_batch'])\n",
            "Script type = None\n",
            "[2021-05-19T16:02:38.320440] Entering Run History Context Manager.\n",
            "[2021-05-19T16:02:38.883209] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/mounts/workspaceblobstore/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad\n",
            "[2021-05-19T16:02:38.883485] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.27.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/mounts/workspaceblobstore/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/inferences', '--input_fds_0', 'diabetes_batch']\n",
            "[2021-05-19T16:02:38.883636] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.27.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/mounts/workspaceblobstore/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/inferences', '--input_fds_0', 'diabetes_batch']\n",
            "\n",
            "2021/05/19 16:02:41 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt\n",
            "===============================================================================================================\n",
            "[2021-05-19T16:03:32.461574] Entering job release\n",
            "[2021-05-19T16:03:33.770558] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-05-19T16:03:33.770612] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-05-19T16:03:33.770671] Running in AzureML-Sidecar, starting to exit user context managers...\n",
            "[2021-05-19T16:03:33.771377] Running Sidecar release cmd...\n",
            "[2021-05-19T16:03:33.782159] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/mounts/workspaceblobstore/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad\n",
            "Enter __exit__ of DatasetContextManager\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/wd/diabetes_batch_eaa144e1-1fc2-4e2b-b611-a47e118b7e7f.\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/oneweek/azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/wd/diabetes_batch_eaa144e1-1fc2-4e2b-b611-a47e118b7e7f.\n",
            "Exit __exit__ of DatasetContextManager\n",
            "[2021-05-19T16:03:33.871155] Removing absolute paths from host...\n",
            "[2021-05-19T16:03:33.883325] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
            "[2021-05-19T16:03:34.532473] Ran Sidecar release cmd.\n",
            "\n",
            "StepRun(batch-score-diabetes) Execution Summary\n",
            "================================================\n",
            "StepRun( batch-score-diabetes ) Status: Finished\n",
            "{'runId': '379ec713-f2b0-4fcb-8e2d-cdde539a94ad', 'target': 'art-cluster-2', 'status': 'Completed', 'startTimeUtc': '2021-05-19T16:01:18.369434Z', 'endTimeUtc': '2021-05-19T16:03:48.553526Z', 'properties': {'ContentSnapshotId': '671ca28f-6ebb-4c47-badf-ea049c83fd81', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '23364924-f811-4968-bb99-1a8490d297b5', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '94eac006', 'azureml.pipelinerunid': 'e779e5a5-00bb-4ca6-a471-fb2b05605021', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': 'eaa144e1-1fc2-4e2b-b611-a47e118b7e7f'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_batch', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.27.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_inferences', '--input_fds_0', 'diabetes_batch'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'art-cluster-2', 'dataReferences': {'inferences': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/inferences', 'pathOnCompute': 'diabetes/results', 'overwrite': False}}, 'data': {'diabetes_batch': {'dataLocation': {'dataset': {'id': 'eaa144e1-1fc2-4e2b-b611-a47e118b7e7f', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_batch', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'batch_environment', 'version': 'Autosave_2021-05-19T15:53:52Z_279867f7', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.27.0', 'azureml-core~=1.27.0', 'azureml-dataprep[fuse]']}, 'scikit-learn', 'pip'], 'name': 'azureml_aa77a7252d8f04306986f9fa8a3997ad'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'dockerContext': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=lP2bvs79fD6EGZ4K4T3dDXofHiQtTw9exiWZ8CJhz5U%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/55_azureml-execution-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt?sv=2019-02-02&sr=b&sig=%2Bu9V2Eaa%2BLmSU8bRORqVYvNvf%2FyEYBqdLxLH4A0xgbU%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/55_azureml-execution-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt?sv=2019-02-02&sr=b&sig=XqszXoCJfRlRCw1IBBpE3BaZ1XLKiP%2B9oUF59kUOYQI%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/65_job_prep-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/65_job_prep-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt?sv=2019-02-02&sr=b&sig=MonaAPbk%2FRcfxz9sEkMHzS7gBvPkFnwD3m5ig1uzzvY%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/65_job_prep-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/65_job_prep-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt?sv=2019-02-02&sr=b&sig=WHdl3pDKdq%2BFNFxCF%2BWAmteuz1M4io8Be1lo9a3M3Og%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=NWdZSN8Pf7LzR21QXMsdj1U4rv7QIEGt3C6jGHF2Foc%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/75_job_post-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/75_job_post-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt?sv=2019-02-02&sr=b&sig=3i8l30LtAs%2BjoOtb%2FARknByjFzY1ilU%2FcrE1wDwUK6k%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/75_job_post-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/75_job_post-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt?sv=2019-02-02&sr=b&sig=hgmyqOz8u35zsW3AJfKvrA6JSDCSQEAapYt6ice6La4%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/process_info.json': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=OX34KtzjJppAaNSKxNuLaDPewr1Vs5ubOMFH1C%2F%2B%2BHY%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/process_status.json': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=nNTt8kSBrh5fBNDNmx%2F6UI%2Bg%2Bad5Zkk5x6I39UFJetE%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/108_azureml.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/108_azureml.log?sv=2019-02-02&sr=b&sig=VYqemu%2Ffkj3H8m0B6Nm7lbdXuz1zm45i82JF5SiKIEU%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/96_azureml.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/96_azureml.log?sv=2019-02-02&sr=b&sig=tE4pfc%2BcTOxQPBKbAz5i%2FWX8dnDhNhczKCNhgZ5Z4E8%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=vys28juI48HelU4%2BixDZ5miOoWyNmPqn69VYuUy9A%2FY%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=Ty87BG0L%2Fw66SUbaWURejCVKI58RAJg%2FlVuTu1qN92M%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=TMkSQymnAKzyfN8xB4pqQWiCNqMPaTGZMcIuyUh71F8%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=gucJBSpnxj70AJAVAe0QMkm5VLVgQSMLxw%2FvstquQtM%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=4fmo88ux8QuJBik%2BuBJyLoxDuAC521bsWACqjiSOMnI%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/all.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/all.log?sv=2019-02-02&sr=b&sig=PgJSxRR3aWzrHlwI9Y%2FQGB4EEKVyLT6zvy8AfUElEPo%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/task.enter_contexts.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=gvsdaQAnvqdP27eFaNJHW9yq%2BbEh60DLHomoD09TAIU%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/task.exit_contexts.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=TTGI%2B%2FW9MN82sMDipLHz2wrXdliRl7DiVmqqhD80%2Fug%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/all.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/all.log?sv=2019-02-02&sr=b&sig=DnFsG18Ue4r75i5an2rYuNneS6pIUOmzRCv4cdNnjik%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/task.enter_contexts.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=otwHXvUFfrXWWxjTq%2Fe2cwTchRUX8gvr0sxHMNh4baI%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/task.exit_contexts.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=LvEWoCLGm9aTMCnoDjM64HlNU2cklTS2mFC30EQBKLA%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=XJfc%2BbZrUO8mDWSU%2BamX%2FNrLSBGunONIjxVBY4sxCNU%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=ZPSJ46llpOkR2joL%2FfVjg6dis1vRcyA86B0HgPVLm8E%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r'}, 'submittedBy': 'Art Sedighi'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': 'e779e5a5-00bb-4ca6-a471-fb2b05605021', 'status': 'Completed', 'startTimeUtc': '2021-05-19T15:52:52.881427Z', 'endTimeUtc': '2021-05-19T16:03:50.36718Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.e779e5a5-00bb-4ca6-a471-fb2b05605021/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=4qRXfW5VPvf79zPCa%2BRTSgDO8dhhQLhfqBGH%2BN63zkg%3D&st=2021-05-19T15%3A53%3A52Z&se=2021-05-20T00%3A03%3A52Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.e779e5a5-00bb-4ca6-a471-fb2b05605021/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=JdwOBbLFZP46JB8ySKR4vI3%2Bk2iBMNL8FXaDAAym81g%3D&st=2021-05-19T15%3A53%3A52Z&se=2021-05-20T00%3A03%3A52Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.e779e5a5-00bb-4ca6-a471-fb2b05605021/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=5BPy1MKdFTtVtG%2FxXs%2FSdPAOlKL%2FtJR53Vyn26vuYX8%3D&st=2021-05-19T15%3A53%3A52Z&se=2021-05-20T00%3A03%3A52Z&sp=r'}, 'submittedBy': 'Art Sedighi'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1621440231072
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the pipeline has finished running, the resulting predictions will have been saved in the outputs of the experiment associated with the first (and only) step in the pipeline. You can retrieve it as follows:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# Remove the local results folder if left over from a previous run\n",
        "shutil.rmtree('diabetes-results', ignore_errors=True)\n",
        "\n",
        "# Get the run for the first step and download its output\n",
        "prediction_run = next(pipeline_run.get_children())\n",
        "prediction_output = prediction_run.get_output_data('inferences')\n",
        "prediction_output.download(local_path='diabetes-results')\n",
        "\n",
        "# Traverse the folder hierarchy and find the results file\n",
        "for root, dirs, files in os.walk('diabetes-results'):\n",
        "    for file in files:\n",
        "        if file.endswith('parallel_run_step.txt'):\n",
        "            result_file = os.path.join(root,file)\n",
        "\n",
        "# cleanup output format\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
        "df.columns = [\"File\", \"Prediction\"]\n",
        "\n",
        "# Display the first 20 results\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "       File  Prediction\n0     1.csv           0\n1    10.csv           1\n2   100.csv           0\n3    11.csv           1\n4    12.csv           0\n5    13.csv           1\n6    14.csv           0\n7    15.csv           0\n8    16.csv           1\n9    17.csv           0\n10   59.csv           1\n11    6.csv           1\n12   60.csv           1\n13   61.csv           0\n14   62.csv           0\n15   40.csv           0\n16   41.csv           0\n17   42.csv           0\n18   43.csv           1\n19   44.csv           0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>13.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>15.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>16.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>17.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>59.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>6.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>60.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>61.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>62.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>40.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>41.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>42.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>43.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>44.csv</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1621440934584
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish the Pipeline and use its REST Interface\n",
        "\n",
        "Now that you have a working pipeline for batch inferencing, you can publish it and use a REST endpoint to run it from an application."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name='diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\n",
        "\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "Pipeline(Name: diabetes-batch-pipeline,\nId: 5aeb2b49-461f-4264-b0ea-f60045aba11b,\nStatus: Active,\nEndpoint: https://eastus.api.azureml.ms/pipelines/v1.0/subscriptions/560f88cc-c40a-468a-81b5-2453d57e1da9/resourceGroups/art-ml-oneweek/providers/Microsoft.MachineLearningServices/workspaces/oneweek/PipelineRuns/PipelineSubmit/5aeb2b49-461f-4264-b0ea-f60045aba11b)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-batch-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/5aeb2b49-461f-4264-b0ea-f60045aba11b?wsid=/subscriptions/560f88cc-c40a-468a-81b5-2453d57e1da9/resourcegroups/art-ml-oneweek/workspaces/oneweek\" target=\"_blank\" rel=\"noopener\">5aeb2b49-461f-4264-b0ea-f60045aba11b</a></td><td>Active</td><td><a href=\"https://eastus.api.azureml.ms/pipelines/v1.0/subscriptions/560f88cc-c40a-468a-81b5-2453d57e1da9/resourceGroups/art-ml-oneweek/providers/Microsoft.MachineLearningServices/workspaces/oneweek/PipelineRuns/PipelineSubmit/5aeb2b49-461f-4264-b0ea-f60045aba11b\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1621440944152
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the published pipeline has an endpoint, which you can see in the Azure portal. You can also find it as a property of the published pipeline object:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://eastus.api.azureml.ms/pipelines/v1.0/subscriptions/560f88cc-c40a-468a-81b5-2453d57e1da9/resourceGroups/art-ml-oneweek/providers/Microsoft.MachineLearningServices/workspaces/oneweek/PipelineRuns/PipelineSubmit/5aeb2b49-461f-4264-b0ea-f60045aba11b\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1621440949847
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. To test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:\n",
        "\n",
        "> **Note**: A real application would require a service principal with which to be authenticated."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()\n",
        "print('Authentication header ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication header ready.\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1621440963443
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it runs:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": \"mslearn-diabetes-batch\"})\n",
        "run_id = response.json()[\"Id\"]\n",
        "run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "'610a090e-0702-4afb-a080-2a4cd30c9701'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1621440969684
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have the run ID, we can use the **RunDetails** widget to view the experiment as it runs:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments['mslearn-diabetes-batch'], run_id)\n",
        "\n",
        "# Block until the run completes\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: 610a090e-0702-4afb-a080-2a4cd30c9701\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/610a090e-0702-4afb-a080-2a4cd30c9701?wsid=/subscriptions/560f88cc-c40a-468a-81b5-2453d57e1da9/resourcegroups/art-ml-oneweek/workspaces/oneweek&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 454d6afd-6345-4937-ac0b-bad656078ed1\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/454d6afd-6345-4937-ac0b-bad656078ed1?wsid=/subscriptions/560f88cc-c40a-468a-81b5-2453d57e1da9/resourcegroups/art-ml-oneweek/workspaces/oneweek&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
            "\n",
            "StepRun(batch-score-diabetes) Execution Summary\n",
            "================================================\n",
            "StepRun( batch-score-diabetes ) Status: Finished\n",
            "{'runId': '454d6afd-6345-4937-ac0b-bad656078ed1', 'target': 'art-cluster-2', 'status': 'Completed', 'startTimeUtc': '2021-05-19T16:16:13.70874Z', 'endTimeUtc': '2021-05-19T16:16:13.775873Z', 'properties': {'azureml.reusedrunid': '379ec713-f2b0-4fcb-8e2d-cdde539a94ad', 'azureml.reusednodeid': '94eac006', 'azureml.reusedpipeline': 'e779e5a5-00bb-4ca6-a471-fb2b05605021', 'azureml.reusedpipelinerunid': 'e779e5a5-00bb-4ca6-a471-fb2b05605021', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '94eac006', 'ContentSnapshotId': '671ca28f-6ebb-4c47-badf-ea049c83fd81', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '23364924-f811-4968-bb99-1a8490d297b5', 'azureml.pipelinerunid': '610a090e-0702-4afb-a080-2a4cd30c9701', 'azureml.pipelineid': '5aeb2b49-461f-4264-b0ea-f60045aba11b', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.27.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_inferences', '--input_fds_0', 'diabetes_batch'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'art-cluster-2', 'dataReferences': {'inferences': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/379ec713-f2b0-4fcb-8e2d-cdde539a94ad/inferences', 'pathOnCompute': 'diabetes/results', 'overwrite': False}}, 'data': {'diabetes_batch': {'dataLocation': {'dataset': {'id': 'eaa144e1-1fc2-4e2b-b611-a47e118b7e7f', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_batch', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'batch_environment', 'version': 'Autosave_2021-05-19T15:53:52Z_279867f7', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.27.0', 'azureml-core~=1.27.0', 'azureml-dataprep[fuse]']}, 'scikit-learn', 'pip'], 'name': 'azureml_aa77a7252d8f04306986f9fa8a3997ad'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'dockerContext': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=lP2bvs79fD6EGZ4K4T3dDXofHiQtTw9exiWZ8CJhz5U%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/55_azureml-execution-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt?sv=2019-02-02&sr=b&sig=%2Bu9V2Eaa%2BLmSU8bRORqVYvNvf%2FyEYBqdLxLH4A0xgbU%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/55_azureml-execution-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt?sv=2019-02-02&sr=b&sig=XqszXoCJfRlRCw1IBBpE3BaZ1XLKiP%2B9oUF59kUOYQI%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/65_job_prep-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/65_job_prep-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt?sv=2019-02-02&sr=b&sig=MonaAPbk%2FRcfxz9sEkMHzS7gBvPkFnwD3m5ig1uzzvY%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/65_job_prep-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/65_job_prep-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt?sv=2019-02-02&sr=b&sig=WHdl3pDKdq%2BFNFxCF%2BWAmteuz1M4io8Be1lo9a3M3Og%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=NWdZSN8Pf7LzR21QXMsdj1U4rv7QIEGt3C6jGHF2Foc%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/75_job_post-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/75_job_post-tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d.txt?sv=2019-02-02&sr=b&sig=3i8l30LtAs%2BjoOtb%2FARknByjFzY1ilU%2FcrE1wDwUK6k%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/75_job_post-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/75_job_post-tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d.txt?sv=2019-02-02&sr=b&sig=hgmyqOz8u35zsW3AJfKvrA6JSDCSQEAapYt6ice6La4%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/process_info.json': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=OX34KtzjJppAaNSKxNuLaDPewr1Vs5ubOMFH1C%2F%2B%2BHY%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'azureml-logs/process_status.json': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=nNTt8kSBrh5fBNDNmx%2F6UI%2Bg%2Bad5Zkk5x6I39UFJetE%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/108_azureml.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/108_azureml.log?sv=2019-02-02&sr=b&sig=VYqemu%2Ffkj3H8m0B6Nm7lbdXuz1zm45i82JF5SiKIEU%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/96_azureml.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/96_azureml.log?sv=2019-02-02&sr=b&sig=tE4pfc%2BcTOxQPBKbAz5i%2FWX8dnDhNhczKCNhgZ5Z4E8%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=vys28juI48HelU4%2BixDZ5miOoWyNmPqn69VYuUy9A%2FY%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=Ty87BG0L%2Fw66SUbaWURejCVKI58RAJg%2FlVuTu1qN92M%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=TMkSQymnAKzyfN8xB4pqQWiCNqMPaTGZMcIuyUh71F8%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=gucJBSpnxj70AJAVAe0QMkm5VLVgQSMLxw%2FvstquQtM%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=4fmo88ux8QuJBik%2BuBJyLoxDuAC521bsWACqjiSOMnI%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/all.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/all.log?sv=2019-02-02&sr=b&sig=PgJSxRR3aWzrHlwI9Y%2FQGB4EEKVyLT6zvy8AfUElEPo%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/task.enter_contexts.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=gvsdaQAnvqdP27eFaNJHW9yq%2BbEh60DLHomoD09TAIU%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/task.exit_contexts.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_659cd5fc2baf9f19a6fd16d7b3fdc4d7a544933cae4a5a9af9dbc476c46be2eb_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=TTGI%2B%2FW9MN82sMDipLHz2wrXdliRl7DiVmqqhD80%2Fug%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/all.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/all.log?sv=2019-02-02&sr=b&sig=DnFsG18Ue4r75i5an2rYuNneS6pIUOmzRCv4cdNnjik%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/task.enter_contexts.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=otwHXvUFfrXWWxjTq%2Fe2cwTchRUX8gvr0sxHMNh4baI%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/task.exit_contexts.log': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/sidecar/tvmps_e1707bf8d3bbd2931bf61cb32eb7c375d0e50f404dc6a993819e8b6c5862b1f5_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=LvEWoCLGm9aTMCnoDjM64HlNU2cklTS2mFC30EQBKLA%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=XJfc%2BbZrUO8mDWSU%2BamX%2FNrLSBGunONIjxVBY4sxCNU%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.379ec713-f2b0-4fcb-8e2d-cdde539a94ad/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=ZPSJ46llpOkR2joL%2FfVjg6dis1vRcyA86B0HgPVLm8E%3D&st=2021-05-19T15%3A53%3A37Z&se=2021-05-20T00%3A03%3A37Z&sp=r'}, 'submittedBy': 'Art Sedighi'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': '610a090e-0702-4afb-a080-2a4cd30c9701', 'status': 'Completed', 'startTimeUtc': '2021-05-19T16:16:11.822475Z', 'endTimeUtc': '2021-05-19T16:16:15.971563Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineid': '5aeb2b49-461f-4264-b0ea-f60045aba11b'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.610a090e-0702-4afb-a080-2a4cd30c9701/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=qdGmH0fjfUpIGf%2Fi3kS0Q4U4%2BYB1Y%2FC2qu9VT%2BZ%2BLPw%3D&st=2021-05-19T16%3A06%3A17Z&se=2021-05-20T00%3A16%3A17Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.610a090e-0702-4afb-a080-2a4cd30c9701/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=hA2YGMjUU1hLwSeQomCk9Te0P2pY9GZYMriwlTxk2VE%3D&st=2021-05-19T16%3A06%3A17Z&se=2021-05-20T00%3A16%3A17Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://oneweek1828054412.blob.core.windows.net/azureml/ExperimentRun/dcid.610a090e-0702-4afb-a080-2a4cd30c9701/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=DEPc6O86EhXvswBvoP5zUXr4sOSAE8YRa%2FgVrzXdXh8%3D&st=2021-05-19T16%3A06%3A17Z&se=2021-05-20T00%3A16%3A17Z&sp=r'}, 'submittedBy': 'Art Sedighi'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1621440975845
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait for the pipeline run to complete, and then run the following cell to see the results.\n",
        "\n",
        "As before, the results are in the output of the first pipeline step:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# Remove the local results folder if left over from a previous run\n",
        "shutil.rmtree('diabetes-results', ignore_errors=True)\n",
        "\n",
        "# Get the run for the first step and download its output\n",
        "prediction_run = next(pipeline_run.get_children())\n",
        "prediction_output = prediction_run.get_output_data('inferences')\n",
        "prediction_output.download(local_path='diabetes-results')\n",
        "\n",
        "# Traverse the folder hierarchy and find the results file\n",
        "for root, dirs, files in os.walk('diabetes-results'):\n",
        "    for file in files:\n",
        "        if file.endswith('parallel_run_step.txt'):\n",
        "            result_file = os.path.join(root,file)\n",
        "\n",
        "# cleanup output format\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
        "df.columns = [\"File\", \"Prediction\"]\n",
        "\n",
        "# Display the first 20 results\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "       File  Prediction\n0     1.csv           0\n1    10.csv           1\n2   100.csv           0\n3    11.csv           1\n4    12.csv           0\n5    13.csv           1\n6    14.csv           0\n7    15.csv           0\n8    16.csv           1\n9    17.csv           0\n10   59.csv           1\n11    6.csv           1\n12   60.csv           1\n13   61.csv           0\n14   62.csv           0\n15   40.csv           0\n16   41.csv           0\n17   42.csv           0\n18   43.csv           1\n19   44.csv           0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>13.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>15.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>16.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>17.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>59.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>6.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>60.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>61.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>62.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>40.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>41.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>42.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>43.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>44.csv</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1621440997458
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have a pipeline that can be used to batch process daily patient data.\n",
        "\n",
        "**More Information**: For more details about using pipelines for batch inferencing, see the [How to Run Batch Predictions](https://docs.microsoft.com/azure/machine-learning/how-to-run-batch-predictions) in the Azure Machine Learning documentation."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}